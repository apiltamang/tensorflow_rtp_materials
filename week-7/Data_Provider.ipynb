{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = set(text)\n",
    "\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "\n",
    "chars = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(chars, batch_size, num_steps, split_frac=0.9):\n",
    "    \"\"\" \n",
    "    Split character data into training and validation sets, inputs and targets for each set.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    chars: character array\n",
    "    batch_size: Size of examples in each of batch\n",
    "    num_steps: Number of sequence steps to keep in the input and pass to the network\n",
    "    split_frac: Fraction of batches to keep in the training set\n",
    "    \n",
    "    \n",
    "    Returns train_x, train_y, val_x, val_y\n",
    "    \"\"\"\n",
    "    print(\"size (chars)\",len(chars))\n",
    "    print(\"batch_size: \",batch_size, \" num_steps: \",num_steps, \" split_frac: \",split_frac)\n",
    "    \n",
    "    slice_size = batch_size * num_steps\n",
    "    print(\"slice_size: \",slice_size)\n",
    "    \n",
    "    n_batches = int(len(chars) / slice_size)\n",
    "    print(\"num_batches: \",n_batches)\n",
    "    \n",
    "    # Drop the last few characters to make only full batches\n",
    "    x = chars[: n_batches*slice_size]\n",
    "    print(\"x: \",x, \"len: \",len(x))\n",
    "    \n",
    "    y = chars[1: n_batches*slice_size + 1]\n",
    "    print(\"y: \",y, \"len: \",len(y))\n",
    "    \n",
    "    # Split the data into batch_size slices, then stack them into a 2D matrix \n",
    "    x = np.stack(np.split(x, batch_size))\n",
    "    print(\"x: \\n\",x, \" shape: \",x.shape)\n",
    "    \n",
    "    y = np.stack(np.split(y, batch_size))\n",
    "    print(\"y: \\n\",y, \" shape: \",y.shape)\n",
    "    # Now x and y are arrays with dimensions batch_size x n_batches*num_steps\n",
    "    \n",
    "    # Split into training and validation sets, keep the virst split_frac batches for training\n",
    "    split_idx = int(n_batches*split_frac)\n",
    "    print(\"split_size: \",split_idx)\n",
    "    print(\"reduced_x_y for training: \",split_idx*num_steps)\n",
    "    \n",
    "    train_x, train_y= x[:, :split_idx*num_steps], y[:, :split_idx*num_steps]\n",
    "    print(\"train_x: \\n\",train_x,\" shape: \",train_x.shape)\n",
    "    print(\"train_y: \\n\",train_y,\" shape: \",train_y.shape)\n",
    "    \n",
    "    val_x, val_y = x[:, split_idx*num_steps:], y[:, split_idx*num_steps:]\n",
    "    print(\"val_x: \\n\",train_x,\" shape: \",val_x.shape)\n",
    "    print(\"val_y: \\n\",train_y,\" shape: \",val_y.shape)\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size (chars) 1985223\n",
      "batch_size:  10000  num_steps:  50  split_frac:  0.9\n",
      "slice_size:  500000\n",
      "num_batches:  3\n",
      "x:  [72 52 81 ..., 74 60  7] len:  1500000\n",
      "y:  [52 81 11 ..., 60  7 69] len:  1500000\n",
      "x: \n",
      " [[72 52 81 ..., 59  3 43]\n",
      " [50 78 59 ..., 76 60 39]\n",
      " [52 78 30 ..., 14 59 81]\n",
      " ..., \n",
      " [30 81 59 ..., 40 43 20]\n",
      " [ 4 32 39 ..., 73 59 81]\n",
      " [20 14 59 ..., 74 60  7]]  shape:  (10000, 150)\n",
      "y: \n",
      " [[52 81 11 ...,  3 43 50]\n",
      " [78 59 52 ..., 60 39 52]\n",
      " [78 30 59 ..., 59 81 20]\n",
      " ..., \n",
      " [81 59  4 ..., 43 20  4]\n",
      " [32 39 18 ..., 59 81 20]\n",
      " [14 59 13 ..., 60  7 69]]  shape:  (10000, 150)\n",
      "split_size:  2\n",
      "reduced_x_y for training:  100\n",
      "train_x: \n",
      " [[72 52 81 ..., 52 43 20]\n",
      " [50 78 59 ..., 59 21 60]\n",
      " [52 78 30 ..., 52 81 14]\n",
      " ..., \n",
      " [30 81 59 ...,  2 43 11]\n",
      " [ 4 32 39 ..., 43 14 59]\n",
      " [20 14 59 ...,  4 60 59]]  shape:  (10000, 100)\n",
      "train_y: \n",
      " [[52 81 11 ..., 43 20 21]\n",
      " [78 59 52 ..., 21 60 40]\n",
      " [78 30 59 ..., 81 14 59]\n",
      " ..., \n",
      " [81 59  4 ..., 43 11  4]\n",
      " [32 39 18 ..., 14 59 81]\n",
      " [14 59 13 ..., 60 59 76]]  shape:  (10000, 100)\n",
      "val_x: \n",
      " [[72 52 81 ..., 52 43 20]\n",
      " [50 78 59 ..., 59 21 60]\n",
      " [52 78 30 ..., 52 81 14]\n",
      " ..., \n",
      " [30 81 59 ...,  2 43 11]\n",
      " [ 4 32 39 ..., 43 14 59]\n",
      " [20 14 59 ...,  4 60 59]]  shape:  (10000, 50)\n",
      "val_y: \n",
      " [[52 81 11 ..., 43 20 21]\n",
      " [78 59 52 ..., 21 60 40]\n",
      " [78 30 59 ..., 81 14 59]\n",
      " ..., \n",
      " [81 59  4 ..., 43 11  4]\n",
      " [32 39 18 ..., 14 59 81]\n",
      " [14 59 13 ..., 60 59 76]]  shape:  (10000, 50)\n"
     ]
    }
   ],
   "source": [
    "#Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps.\n",
    "train_x, train_y, val_x, val_y = split_data(chars, batch_size=10000, num_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"train_x.npy\",train_x)\n",
    "np.save(\"train_y.npy\",train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batches(train_x, train_y, batch_size):\n",
    "    for i in range(0, train_x.shape[0], batch_size):\n",
    "        print(\"getting: \",i,\" to \", i+batch_size)\n",
    "        yield train_x[i : i+batch_size], train_y[i : i+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the below so that other files can use it for generating texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('vocab_to_int.txt','ab+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(vocab_to_int,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output2 = open('int_to_vocab.txt','ab+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(int_to_vocab, output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
