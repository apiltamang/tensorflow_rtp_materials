{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with an RNN\n",
    "\n",
    "In this notebook, we will implement a recurrent neural network that performs sentiment analysis. Using an RNN rather than a feedfoward network is more accurate since we can include information about the sequence of words. Here we'll use a dataset of movie reviews, accompanied by labels.\n",
    "The architecture for this network is shown below.\n",
    "\n",
    "![Imgur](http://i.imgur.com/1elbD2U.png?1)\n",
    "\n",
    "\n",
    "Here, we'll pass in words to an embedding layer. We need an embedding layer because we have tens of thousands of words, so we'll need a more efficient representation for our input data than one-hot encoded vectors. You should have seen this before from the word2vec lesson. You can actually train up an embedding with word2vec and use it here. But it's good enough to just have an embedding layer and let the network learn the embedding table on it's own.\n",
    "From the embedding layer, the new representations will be passed to LSTM cells. These will add recurrent connections to the network so we can include information about the sequence of words in the data. Finally, the LSTM cells will go to a sigmoid output layer here. We're using the sigmoid because we're trying to predict if this text has positive or negative sentiment. The output layer will just be a single unit then, with a sigmoid activation function.\n",
    "We don't care about the sigmoid outputs except for the very last one, we can ignore the rest. We'll calculate the cost from the output of the last step and the training label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from the binary files\n",
    "Highly recommeded to look at the Data_Provider notebook attached in the same folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.load(\"train_x.npy\")\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "\n",
    "val_x = np.load(\"val_x.npy\")\n",
    "val_y = np.load(\"val_y.npy\")\n",
    "\n",
    "test_x = np.load(\"test_x.npy\")\n",
    "test_y = np.load(\"test_y.npy\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "vocab_to_int = pickle.load(open('vocab_to_int','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create the input, output placeholders\n",
    "First, as always, start by defining some input data placeholders. Give you a place to anchor your ideas..\n",
    "\n",
    "input\\_ : [batch\\_size, seq\\_length]\n",
    "\n",
    "output\\_ : [batch\\_size, 1] \n",
    "\n",
    "The 1 denotes a one dimensional value describing if it is a positive (value=1) or negative (value=0) sentiment. Also, I suppose the batch_size placeholder is something I haven't used before in CNNs or regular dense architectures, but is required for LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_ = tf.placeholder(tf.int32, shape=[None, None])\n",
    "output_ = tf.placeholder(tf.int32, shape=[None])\n",
    "batch_size_ = tf.placeholder(tf.int32)\n",
    "dropout_ = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int) # Evaluate the total num of words we'll have\n",
    "seq_length = 200 # The length of the timestep we will be using\n",
    "embed_size = 300 # The size of the embedding vector for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the embedding layer, with the embedding lookup method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = tf.Variable(tf.truncated_normal(shape=[n_words, embed_size], mean=0., stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vector = tf.nn.embedding_lookup(embedding_matrix, input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the shape of the embedding_vector shape is:  [None, None, 300] (batch_size, seq_length, embed_size). I.e. it effectively takes each word and projects that in a vector of size 'embed_size'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LSTM Cell, apply dropout, and create a multi-layered unit\n",
    "Very standard way of creating a multi-layered LSTM architecture, also using dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_lstm = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=dropout_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_lstm_layers = 2\n",
    "cell = tf.contrib.rnn.MultiRNNCell([dropout_lstm]*num_lstm_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use dynamic_rnn to perform dynamic time unfolding. \n",
    "This also requires that we create an initial_state (which we will set to zeros). At the end of this, we collect the outputs and final_state from the dynamic_rnn method. These values: *outputs* and *final_state* are quite interesting. It is worth checking them out in the original docs. A little bit of additional information is listed here: \n",
    "https://github.com/apiltamang/tensorflow_rtp_materials/blob/master/week-7/Tensorflow_BasicLSTMCell_and_Embeddings.ipynb. \n",
    "\n",
    "In order to really understand what they [outputs,final_states] are, look at the method: step(..) in the notebook: https://github.com/apiltamang/tensorflow_rtp_materials/blob/master/week-7/Vanilla_LSTM_Using_Embeddings.ipynb. What they are is a tuple containing the exposed state ($s_t$) and internal state ($c_t$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_state = cell.zero_state(batch_size_, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, final_state = tf.nn.dynamic_rnn(cell, embedding_vector, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Output: We'll only keep the output from the final time-step. \n",
    "The outputs vector contains the encoded information from all batches, across all time-steps, projected in the size of the LSTM layer, i.e (batch_size, time_step, num_units). Only get the last time unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_time_state = outputs[:,-1,:] # (batch_size, num_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect LSTM to a Dense layer\n",
    "Connect the output vector from LSTM to a dense layer, and squeeze it to a value between 0 and 1 using the sigmoid activation. Because this problem has only two labels (positive, negative) we can afford to have a single unit for the dense layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "cost = tf.losses.mean_squared_error(output_, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massage the targets (or labels) vectors so that it is a two dimensional tensor. At the data source-level, the targets is a 1-D array, e.g. [1 0 0 0 1 0 1 0 1 0 0 1 ... 0 0 1]. Instead reshape it so that it looks as follows:\n",
    "[ [1]\n",
    "  [0]\n",
    "  [0]\n",
    "  .\n",
    "  .\n",
    "  .\n",
    "  [0]\n",
    "  [1]\n",
    "]. We do this to cast it to the output placeholder (output\\_) defined at the very beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_reshape = tf.reshape(output_, [-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss functions\n",
    "Very standard way of defining costs/optimizer etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.losses.mean_squared_error(output_reshape, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), output_)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  0 batch:  10 , loss evaluated:  0.226663\n",
      "epochs:  0 batch:  20 , loss evaluated:  0.284504\n",
      "Val acc: 0.500\n",
      "epochs:  1 batch:  10 , loss evaluated:  0.0556807\n",
      "epochs:  1 batch:  20 , loss evaluated:  0.208611\n",
      "Val acc: 0.500\n",
      "epochs:  2 batch:  10 , loss evaluated:  0.041939\n",
      "epochs:  2 batch:  20 , loss evaluated:  0.0575101\n",
      "Val acc: 0.500\n",
      "epochs:  3 batch:  10 , loss evaluated:  0.0292734\n",
      "epochs:  3 batch:  20 , loss evaluated:  0.056139\n",
      "Val acc: 0.500\n",
      "epochs:  4 batch:  10 , loss evaluated:  0.00526734\n",
      "epochs:  4 batch:  20 , loss evaluated:  0.02884\n",
      "Val acc: 0.500\n",
      "epochs:  5 batch:  10 , loss evaluated:  0.000238991\n",
      "epochs:  5 batch:  20 , loss evaluated:  0.0200906\n",
      "Val acc: 0.500\n",
      "epochs:  6 batch:  10 , loss evaluated:  0.0159842\n",
      "epochs:  6 batch:  20 , loss evaluated:  0.00475118\n",
      "Val acc: 0.500\n",
      "epochs:  7 batch:  10 , loss evaluated:  9.49389e-05\n",
      "epochs:  7 batch:  20 , loss evaluated:  0.000919348\n",
      "Val acc: 0.500\n",
      "epochs:  8 batch:  10 , loss evaluated:  0.0047845\n",
      "epochs:  8 batch:  20 , loss evaluated:  0.000325212\n",
      "Val acc: 0.500\n",
      "epochs:  9 batch:  10 , loss evaluated:  0.000358632\n",
      "epochs:  9 batch:  20 , loss evaluated:  0.000130162\n",
      "Val acc: 0.500\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-dc38f2f95c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Val acc: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"checkpoints/sentiment_rnn.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saver' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_loss = 0.\n",
    "    n_epochs = 10\n",
    "    for i in range(n_epochs):\n",
    "        counter = 0\n",
    "        for xs, ys in get_batches(train_x[0:2000], train_y[0:2000], batch_size=100):\n",
    "            counter += 1\n",
    "            _, train_loss_val = sess.run([optimizer, cost], \n",
    "                                         feed_dict={input_: xs, output_: ys, dropout_: 0.8, batch_size_:100, learning_rate: 0.01})\n",
    "            if(counter%10==0):\n",
    "                print(\"epochs: \",i, \"batch: \",counter, \", loss evaluated: \",train_loss_val)\n",
    "            \n",
    "        # do validation at the end of epochs\n",
    "        val_acc = []\n",
    "        val_state = sess.run(cell.zero_state(batch_size_, tf.float32), feed_dict={batch_size_:100})\n",
    "        for xs, ys in get_batches(val_x, val_y, batch_size=100):\n",
    "\n",
    "            batch_acc, val_state = sess.run([accuracy, final_state], \n",
    "                                        feed_dict={input_: xs, output_: ys, dropout_: 1, initial_state: val_state})\n",
    "            val_acc.append(batch_acc)\n",
    "        print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            \n",
    "    saver.save(sess, \"checkpoints/sentiment_rnn.ckpt\")            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
